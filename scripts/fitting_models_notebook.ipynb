{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import build_master_df\n",
    "import pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Google mobility data...\n",
      "Reading / merging NAICS business pattern data...\n",
      "Reading / merging ACS census data...\n",
      "Reading / merging CDC health data...\n",
      "    Interpolating missing CDC county data with state data...\n",
      "    Dropping extra CDC columns...\n",
      "Reading / merging CDC cases and death data...\n",
      "Reading / merging NOAA weather data...\n",
      "\tInterpolating missing weather data\n",
      "\tInterpolating TMAX...\n",
      "\tInterpolating TMIN...\n",
      "\tInterpolating PRCP...\n",
      "\tInterpolating TMIN_3d_avg...\n",
      "\tInterpolating TMIN_5d_avg...\n",
      "\tInterpolating TMIN_7d_avg...\n",
      "\tInterpolating TMIN_10d_avg...\n",
      "\tInterpolating TMAX_3d_avg...\n",
      "\tInterpolating TMAX_5d_avg...\n",
      "\tInterpolating TMAX_7d_avg...\n",
      "\tInterpolating TMAX_10d_avg...\n",
      "\tCreating precipiation dummy...\n",
      "Reading interventions data...\n",
      "\tTransforming intervention columns...\n",
      "\tTransforming int_date_public schools...\n",
      "\tTransforming int_date_restaurant dine-in...\n",
      "\tTransforming int_date_federal guidelines...\n",
      "\tTransforming int_date_foreign travel ban...\n",
      "Reading vote share data...\n",
      "Outputting csv..\n"
     ]
    }
   ],
   "source": [
    "raw = build_master_df.build_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Identify variables\n",
    "index_vars   = ['StateName','CountyName','fips','date']\n",
    "target_vars  = [col for col in raw.columns if (col.endswith('change_from_baseline'))]\n",
    "main_target  = 'retail_and_recreation_percent_change_from_baseline'\n",
    "features     = [col for col in raw.columns if (col not in index_vars) and (col not in target_vars)]\n",
    "\n",
    "# Get full dataset for use\n",
    "df = raw.dropna(subset=[main_target])[features+[main_target]+['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train test \n",
    "train_full,validation_full,test_full = pipeline.get_train_test(df,train_size=0.8,\n",
    "                                                               time_series=True,validation=True)\n",
    "train_target = train_full[main_target]\n",
    "validation_target = validation_full[main_target]\n",
    "test_target = test_full[main_target]\n",
    "train_features = train_full.drop(columns=[main_target])\n",
    "validation_features = validation_full.drop(columns=[main_target])\n",
    "test_features = test_full.drop(columns=[main_target])\n",
    "\n",
    "# Impute and normalize\n",
    "train_features,validation_features,test_features = pipeline.impute_missing(train_features,test_features,\n",
    "                                                                           validation_features,how='median')\n",
    "train_features,validation_features,test_features = pipeline.normalize_vars(train_features,test_features,\n",
    "                                                                           validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify number of components that explain 95% of variance\n",
    "pca = PCA(n_components=75)\n",
    "pca.fit(train_features)\n",
    "cumsums = np.cumsum(pca.explained_variance_ratio_)\n",
    "num_components = next(x for x,val in enumerate(cumsums) if val > 0.95)+1\n",
    "\n",
    "\n",
    "pca = PCA(n_components=num_components)\n",
    "pca.fit(train_features)\n",
    "train_pca_features = pca.transform(train_features)\n",
    "validation_pca_features = pca.transform(validation_features)\n",
    "test_pca_features  = pca.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "build_regressors() missing 1 required positional argument: 'save_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5ee4e249fafa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m model_results = pipeline.build_regressors(MODELS, GRID,\n\u001b[0;32m     35\u001b[0m                                           \u001b[0mtrain_pca_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m                                           test_pca_features, test_target)\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: build_regressors() missing 1 required positional argument: 'save_path'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Config: Dictionaries of models and hyperparameters\n",
    "MODELS = {\n",
    "    'LinearRegression': LinearRegression(), \n",
    "    'Lasso': Lasso(),\n",
    "    'Ridge': Ridge(),\n",
    "    'LinearSVR': LinearSVR(), \n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'AdaBoostRegressor':AdaBoostRegressor(),\n",
    "    'KNeighborsRegressor':KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "\n",
    "GRID = {\n",
    "    'LinearRegression': [{}],\n",
    "    'Lasso': [{'alpha':x, 'random_state':0, 'max_iter':10000} for x in [0.01,0.05,0.1,0.5,1,5,10,50,100,500,1000]],\n",
    "    'Ridge': [{'alpha':x, 'random_state':0, 'max_iter':10000} for x in [0.01,0.05,0.1,0.5,1,5,10,50,100,500,1000]],\n",
    "    'LinearSVR': [{'C': x, 'epsilon':y, 'random_state': 0, 'max_iter':10000} \\\n",
    "                  for x in [0.01,0.05,0.1,0.5,1,5]\n",
    "                  for y in [0.01,0.1,1]],\n",
    "    'RandomForestRegressor': [{'n_estimators':x, 'max_features':y,\n",
    "                               'n_jobs':-1} \\\n",
    "                               for y in ['auto','log2','sqrt']\n",
    "                               for x in [100,500,1000]],\n",
    "    'AdaBoostRegressor': [{'n_estimators':y} for y in [50, 100, 150]],\n",
    "    'KNeighborsRegressor': [{'n_neighbors':x} for x in np.arange(5,20)]\n",
    "}\n",
    "\n",
    "model_results = pipeline.build_regressors(MODELS, GRID,\n",
    "                                          train_pca_features, train_target,\n",
    "                                          test_pca_features, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbasecondae5518070c05049a0bb304b0bfde257d3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
